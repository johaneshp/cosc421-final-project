knitr::opts_chunk$set(echo = TRUE)
# this file is for do some most basic analysis to the data we collected.
data <- read_csv("data/papers_clean1.csv")
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(readr)
library(readr)
library(readr)
library(readr)
library(readr)
library(readr)
library(readr)
library(readr)
# this file is for do some most basic analysis to the data we collected.
data <- read_csv("data/papers_clean1.csv")
# this file is for do some most basic analysis to the data we collected.
data <- read_csv("/data/papers_clean1.csv")
# this file is for do some most basic analysis to the data we collected.
data <- read_csv("/data/nodes.csv")
# this file is for do some most basic analysis to the data we collected.
data <- read_csv("data/nodes.csv")
# head of data
head(data)
# row and colum number
dim(data)
# colum names
names(data)
# type of colums
str(data)
# summary
summary(data)
knitr::opts_chunk$set(echo = TRUE)
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
dim(edges)
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
# number of cititations
dim(edges)
# form graph
graph <- graph_from_data_frame(edges, nodes, directed = FALSE)
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
# number of cititations
dim(edges)
# form graph
graph <- graph_from_data_frame(edges, nodes, directed = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(igraph)
set.seed(48528608)
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
# number of cititations
dim(edges)
# form graph
graph <- graph_from_data_frame(edges, nodes, directed = FALSE)
# remove the parallel edges and self loops
graph <- simplify(graph, remove.multiple = TRUE, remove.loops = TRUE)
vcount(graph)
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
# number of cititations
dim(edges)
# form graph
graph <- graph_from_data_frame(edges, nodes, directed = FALSE)
# remove the parallel edges and self loops
graph <- simplify(graph, remove.multiple = TRUE, remove.loops = TRUE)
# nodes in graph
vcount(graph)
# edges in graph
ecount(graph)
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
# number of cititations
dim(edges)
# form graph
graph <- graph_from_data_frame(edges, nodes, directed = FALSE)
# remove the parallel edges and self loops
graph <- simplify(graph, remove.multiple = TRUE, remove.loops = TRUE)
# nodes in graph
vcount(graph)
# edges in graph
ecount(graph)
# plot graph (color by university)
plot(graph, vertex.size=5, edge.arrow.size=0.5, vertex.color=V(graph)$institution,
main = "Over all of the graph (colored by university)", vertex.label=NA)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(igraph)
library(RColorBrewer)
set.seed(48528608)
# this file is for do some most basic analysis to the data we collected.
nodes <- read.csv("data/nodes.csv")
# head of data
head(nodes)
# row and colum number
dim(nodes)
# colum names
names(nodes)
# type of colums
str(nodes)
# summary
summary(nodes)
# read edge
edges = read.csv("data/edges.csv")
# number of cititations
dim(edges)
# form graph
graph <- graph_from_data_frame(edges, nodes, directed = FALSE)
# remove the parallel edges and self loops
graph <- simplify(graph, remove.multiple = TRUE, remove.loops = TRUE)
# nodes in graph
vcount(graph)
# edges in graph
ecount(graph)
# plot graph (color by university)
institutions <- unique(V(graph)$institution)
palette <- brewer.pal(min(length(institutions), 8), "Set2")
color_map <- setNames(rep(palette, length.out = length(institutions)), institutions)
V(graph)$color <- color_map[V(graph)$institution]
plot(graph, vertex.size=5, edge.arrow.size=0.5, vertex.color=V(graph)$color,
main="Overall network (colored by university)", vertex.label=NA)
# plot graph (color by university)
institutions <- unique(V(graph)$institution)
palette <- brewer.pal(min(length(institutions), 8), "Set2")
color_map <- setNames(rep(palette, length.out = length(institutions)), institutions)
V(graph)$color <- color_map[V(graph)$institution]
plot(graph, vertex.size=2, edge.arrow.size=0.1, vertex.color=V(graph)$color,
main="Overall network (colored by university)", vertex.label=NA)
# plot graph (color by university)
institutions <- unique(V(graph)$institution)
palette <- brewer.pal(min(length(institutions), 8), "Set2")
color_map <- setNames(rep(palette, length.out = length(institutions)), institutions)
V(graph)$color <- color_map[V(graph)$institution]
plot(graph, vertex.size=2, edge.size=0.1, vertex.color=V(graph)$color,
main="Overall network (colored by university)", vertex.label=NA)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(igraph)
library(RColorBrewer)
library(ggplot2)
library(reshape2)
library(scales)
library(gridExtra)
set.seed(48528608)
# Load the connected nodes and edges data
nodes_connected <- read.csv("data/nodes_connected.csv")
edges_connected <- read.csv("data/edges_connected.csv")
cat("=== DATA LOADING ===\n")
cat("Connected nodes loaded:", nrow(nodes_connected), "\n")
cat("Connected edges loaded:", nrow(edges_connected), "\n\n")
# Create the graph from connected nodes only
graph_connected <- graph_from_data_frame(edges_connected,
vertices = nodes_connected,
directed = TRUE)
# Remove multiple edges and self-loops for cleaner analysis
graph_connected <- simplify(graph_connected,
remove.multiple = TRUE,
remove.loops = TRUE)
cat("Graph created successfully\n")
cat("Final nodes in graph:", vcount(graph_connected), "\n")
cat("Final edges in graph:", ecount(graph_connected), "\n\n")
cat("=== BASIC GRAPH STATISTICS ===\n")
cat("Total nodes:", vcount(graph_connected), "\n")
cat("Total edges (citations):", ecount(graph_connected), "\n")
cat("Network density:", round(edge_density(graph_connected), 6), "\n")
cat("Is directed:", is_directed(graph_connected), "\n")
cat("Is weighted:", is_weighted(graph_connected), "\n\n")
# Calculate degree statistics
all_degrees <- degree(graph_connected, mode = "all")
in_degrees <- degree(graph_connected, mode = "in")
out_degrees <- degree(graph_connected, mode = "out")
cat("=== DEGREE STATISTICS ===\n")
cat("Average total degree:", round(mean(all_degrees), 2), "\n")
cat("Average in-degree (citations received):", round(mean(in_degrees), 2), "\n")
cat("Average out-degree (citations made):", round(mean(out_degrees), 2), "\n\n")
cat("Degree range (total):", min(all_degrees), "-", max(all_degrees), "\n")
cat("Degree range (in):", min(in_degrees), "-", max(in_degrees), "\n")
cat("Degree range (out):", min(out_degrees), "-", max(out_degrees), "\n\n")
cat("Standard deviation (total):", round(sd(all_degrees), 2), "\n")
cat("Standard deviation (in):", round(sd(in_degrees), 2), "\n")
cat("Standard deviation (out):", round(sd(out_degrees), 2), "\n\n")
cat("=== COMPONENT ANALYSIS ===\n")
# Analyze weakly connected components
weak_components <- components(graph_connected, mode = "weak")
cat("Number of weakly connected components:", weak_components$no, "\n")
cat("Size of largest weak component:", max(weak_components$csize), "\n")
cat("Proportion of nodes in largest weak component:",
round(max(weak_components$csize) / vcount(graph_connected) * 100, 2), "%\n\n")
# Analyze strongly connected components
strong_components <- components(graph_connected, mode = "strong")
cat("Number of strongly connected components:", strong_components$no, "\n")
cat("Size of largest strong component:", max(strong_components$csize), "\n")
cat("Proportion of nodes in largest strong component:",
round(max(strong_components$csize) / vcount(graph_connected) * 100, 2), "%\n\n")
# Component size distribution
cat("Weak component sizes (top 10):\n")
weak_sizes <- sort(weak_components$csize, decreasing = TRUE)
print(head(weak_sizes, 10))
cat("\nStrong component sizes (top 10):\n")
strong_sizes <- sort(strong_components$csize, decreasing = TRUE)
print(head(strong_sizes, 10))
# Create comprehensive degree distribution analysis
# Prepare data for plotting
degree_data <- data.frame(
node_id = V(graph_connected)$name,
total_degree = all_degrees,
in_degree = in_degrees,
out_degree = out_degrees
)
# Add node attributes for additional analysis
degree_data$institution <- V(graph_connected)$institution
degree_data$subtopic <- V(graph_connected)$subtopic
degree_data$year <- V(graph_connected)$year
degree_data$citations <- V(graph_connected)$citations
cat("=== DEGREE DISTRIBUTION SUMMARY ===\n")
cat("Total degree quartiles:\n")
print(quantile(all_degrees))
cat("\nIn-degree quartiles:\n")
print(quantile(in_degrees))
cat("\nOut-degree quartiles:\n")
print(quantile(out_degrees))
# In-degree distribution histogram
ggplot(degree_data, aes(x = in_degree)) +
geom_histogram(binwidth = 1, fill = "lightblue", alpha = 0.7, color = "white") +
labs(title = "In-Degree Distribution (Citations Received)",
subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
x = "In-Degree (Citations Received)",
y = "Frequency") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5)) +
scale_x_continuous(breaks = seq(0, max(in_degrees), by = 5))
# Print summary statistics
cat("\nIN-DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(in_degrees), 2), "\n")
cat("Median:", median(in_degrees), "\n")
cat("Mode:", names(sort(table(in_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with 0 in-degree:", sum(in_degrees == 0), "\n")
cat("Nodes with >10 in-degree:", sum(in_degrees > 10), "\n")
# Out-degree distribution histogram
ggplot(degree_data, aes(x = out_degree)) +
geom_histogram(binwidth = 1, fill = "lightcoral", alpha = 0.7, color = "white") +
labs(title = "Out-Degree Distribution (Citations Made)",
subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
x = "Out-Degree (Citations Made)",
y = "Frequency") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5)) +
scale_x_continuous(breaks = seq(0, max(out_degrees), by = 5))
# Print summary statistics
cat("\nOUT-DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(out_degrees), 2), "\n")
cat("Median:", median(out_degrees), "\n")
cat("Mode:", names(sort(table(out_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with 0 out-degree:", sum(out_degrees == 0), "\n")
cat("Nodes with >10 out-degree:", sum(out_degrees > 10), "\n")
# Total degree distribution histogram
ggplot(degree_data, aes(x = total_degree)) +
geom_histogram(binwidth = 2, fill = "lightgreen", alpha = 0.7, color = "white") +
labs(title = "Total Degree Distribution",
subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
x = "Total Degree (In + Out)",
y = "Frequency") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5)) +
scale_x_continuous(breaks = seq(0, max(all_degrees), by = 10))
# Print summary statistics
cat("\nTOTAL DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(all_degrees), 2), "\n")
cat("Median:", median(all_degrees), "\n")
cat("Mode:", names(sort(table(all_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with degree 1:", sum(all_degrees == 1), "\n")
cat("Nodes with degree >20:", sum(all_degrees > 20), "\n")
# Create combined degree distribution plot
degree_long <- reshape2::melt(degree_data[, c("in_degree", "out_degree", "total_degree")],
variable.name = "degree_type",
value.name = "degree_value")
# Rename for better labels
degree_long$degree_type <- factor(degree_long$degree_type,
levels = c("in_degree", "out_degree", "total_degree"),
labels = c("In-Degree", "Out-Degree", "Total Degree"))
# Create faceted histogram
ggplot(degree_long, aes(x = degree_value, fill = degree_type)) +
geom_histogram(alpha = 0.7, color = "white", bins = 30) +
facet_wrap(~degree_type, scales = "free") +
scale_fill_manual(values = c("In-Degree" = "lightblue",
"Out-Degree" = "lightcoral",
"Total Degree" = "lightgreen")) +
labs(title = "Degree Distribution Comparison",
subtitle = "In-Degree vs Out-Degree vs Total Degree",
x = "Degree Value",
y = "Frequency") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5),
legend.position = "none",
strip.text = element_text(face = "bold"))
# Analyze the largest component in detail
cat("=== LARGEST COMPONENT DETAILED ANALYSIS ===\n")
# Extract the largest weakly connected component
largest_comp_nodes <- which(weak_components$membership == which.max(weak_components$csize))
largest_component <- induced_subgraph(graph_connected, largest_comp_nodes)
cat("Largest component statistics:\n")
cat("Nodes:", vcount(largest_component), "\n")
cat("Edges:", ecount(largest_component), "\n")
cat("Density:", round(edge_density(largest_component), 6), "\n")
cat("Average in degree:", round(mean(degree(largest_component, mode = "in")), 2), "\n")
cat("Average out degree:", round(mean(degree(largest_component, mode = "out")), 2), "\n")
cat("Average degree:", round(mean(degree(largest_component, mode = "all")), 2), "\n")
cat("Diameter:", diameter(largest_component, directed = FALSE), "\n")
cat("Average path length:", round(mean_distance(largest_component, directed = FALSE), 2), "\n\n")
# Check if there are smaller components worth analyzing
if(length(unique(weak_components$csize)) > 1) {
second_largest_size <- sort(weak_components$csize, decreasing = TRUE)[2]
cat("Second largest component size:", second_largest_size, "\n")
cat("Ratio (largest/second largest):", round(max(weak_components$csize) /
second_largest_size, 2), "\n")
}
cat("=== CENTRALITY ANALYSIS OF LARGEST COMPONENT ===\n")
# Calculate various centrality measures
cat("Calculating centrality measures...\n")
# Degree centrality (already calculated above)
degree_cent_in <- degree(largest_component, mode = "in", normalized = TRUE)
degree_cent_out <- degree(largest_component, mode = "out", normalized = TRUE)
degree_cent_all <- degree(largest_component, mode = "all", normalized = TRUE)
# Betweenness centrality
betweenness_cent <- betweenness(largest_component, directed = TRUE, normalized = TRUE)
# Closeness centrality
closeness_cent_in <- closeness(largest_component, mode = "in", normalized = TRUE)
closeness_cent_out <- closeness(largest_component, mode = "out", normalized = TRUE)
# Eigenvector centrality
eigenvector_cent <- eigen_centrality(largest_component, directed = TRUE, scale = TRUE)$vector
# PageRank centrality
pagerank_cent <- page_rank(largest_component, directed = TRUE)$vector
# Authority and Hub scores (HITS algorithm)
hits_scores <- hub_score(largest_component)
hub_cent <- hits_scores$vector
authority_cent <- authority_score(largest_component)$vector
cat("All centrality measures calculated successfully!\n\n")
# Create centrality summary
centrality_summary <- data.frame(
node_id = V(largest_component)$name,
degree_in = degree_cent_in,
degree_out = degree_cent_out,
degree_all = degree_cent_all,
betweenness = betweenness_cent,
closeness_in = closeness_cent_in,
closeness_out = closeness_cent_out,
eigenvector = eigenvector_cent,
pagerank = pagerank_cent,
hub = hub_cent,
authority = authority_cent
)
eigenvector
cat("=== CENTRALITY ANALYSIS OF LARGEST COMPONENT ===\n")
# Calculate various centrality measures
cat("Calculating centrality measures...\n")
# Degree centrality (already calculated above)
degree_cent_in <- degree(largest_component, mode = "in", normalized = TRUE)
degree_cent_out <- degree(largest_component, mode = "out", normalized = TRUE)
degree_cent_all <- degree(largest_component, mode = "all", normalized = TRUE)
# Betweenness centrality
betweenness_cent <- betweenness(largest_component, directed = TRUE, normalized = TRUE)
# Closeness centrality
closeness_cent_in <- closeness(largest_component, mode = "in", normalized = TRUE)
closeness_cent_out <- closeness(largest_component, mode = "out", normalized = TRUE)
# Eigenvector centrality
eigenvector_cent <- eigen_centrality(largest_component, directed = TRUE, scale = TRUE)$vector
# PageRank centrality
pagerank_cent <- page_rank(largest_component, directed = TRUE)$vector
# Authority and Hub scores (HITS algorithm)
hits_scores <- hub_score(largest_component)
hub_cent <- hits_scores$vector
authority_cent <- authority_score(largest_component)$vector
cat("All centrality measures calculated successfully!\n\n")
# Create centrality summary
centrality_summary <- data.frame(
node_id = V(largest_component)$name,
degree_in = degree_cent_in,
degree_out = degree_cent_out,
degree_all = degree_cent_all,
betweenness = betweenness_cent,
closeness_in = closeness_cent_in,
closeness_out = closeness_cent_out,
eigenvector = eigenvector_cent,
pagerank = pagerank_cent,
hub = hub_cent,
authority = authority_cent
)
centrality_summary$eigenvector
# Print top nodes by different centrality measures
cat("TOP 5 NODES BY DIFFERENT CENTRALITY MEASURES:\n\n")
cat("Highest In-Degree Centrality (most cited):\n")
top_in_degree <- centrality_summary[order(centrality_summary$degree_in, decreasing = TRUE)[1:5],
c("node_id", "degree_in")]
print(top_in_degree)
cat("\nHighest PageRank (most influential):\n")
top_pagerank <- centrality_summary[order(centrality_summary$pagerank, decreasing = TRUE)[1:5],
c("node_id", "pagerank")]
print(top_pagerank)
cat("\nHighest Betweenness Centrality (most important bridges):\n")
top_betweenness <- centrality_summary[order(centrality_summary$betweenness, decreasing = TRUE)[1:5],
c("node_id", "betweenness")]
print(top_betweenness)
cat("\nHighest Authority Score (most authoritative):\n")
top_authority <- centrality_summary[order(centrality_summary$authority, decreasing = TRUE)[1:5],
c("node_id", "authority")]
print(top_authority)
