---
title: "Deeper analysis and Network statistics"
author: "Jinxi_Hu-48528608, Samarth_Grover-38220463"
date: "2025-11-09"
output: 
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## set up
```{r set up,message = FALSE, warning = FALSE}
library(readr)
library(igraph)
library(RColorBrewer)
library(ggplot2)
library(reshape2)
library(scales)
library(gridExtra)
set.seed(48528608)
```

## Load and prepare connected nodes data (Jinxi Hu)

```{r load-connected-data}
# Load the connected nodes and edges data
nodes_connected <- read.csv("data/nodes_connected.csv")
edges_connected <- read.csv("data/edges_connected.csv")

cat("=== DATA LOADING ===\n")
cat("Connected nodes loaded:", nrow(nodes_connected), "\n")
cat("Connected edges loaded:", nrow(edges_connected), "\n\n")

# Create the graph from connected nodes only
graph_connected <- graph_from_data_frame(edges_connected, 
                                        vertices = nodes_connected, 
                                        directed = TRUE)
# Remove multiple edges and self-loops for cleaner analysis
graph_connected <- simplify(graph_connected, 
                          remove.multiple = TRUE, 
                          remove.loops = TRUE)

cat("Graph created successfully\n")
cat("Final nodes in graph:", vcount(graph_connected), "\n")
cat("Final edges in graph:", ecount(graph_connected), "\n\n")
```

## Basic Graph Analysis (Jinxi Hu)

```{r basic-graph-analysis}
cat("=== BASIC GRAPH STATISTICS ===\n")
cat("Total nodes:", vcount(graph_connected), "\n")
cat("Total edges (citations):", ecount(graph_connected), "\n")
cat("Network density:", round(edge_density(graph_connected), 6), "\n")
cat("Is directed:", is_directed(graph_connected), "\n")
cat("Is weighted:", is_weighted(graph_connected), "\n\n")

# Calculate degree statistics
all_degrees <- degree(graph_connected, mode = "all")
in_degrees <- degree(graph_connected, mode = "in")
out_degrees <- degree(graph_connected, mode = "out")

cat("=== DEGREE STATISTICS ===\n")
cat("Average total degree:", round(mean(all_degrees), 2), "\n")
cat("Average in-degree (citations received):", round(mean(in_degrees), 2), "\n")
cat("Average out-degree (citations made):", round(mean(out_degrees), 2), "\n\n")

cat("Degree range (total):", min(all_degrees), "-", max(all_degrees), "\n")
cat("Degree range (in):", min(in_degrees), "-", max(in_degrees), "\n")
cat("Degree range (out):", min(out_degrees), "-", max(out_degrees), "\n\n")

cat("Standard deviation (total):", round(sd(all_degrees), 2), "\n")
cat("Standard deviation (in):", round(sd(in_degrees), 2), "\n")
cat("Standard deviation (out):", round(sd(out_degrees), 2), "\n\n")
```

```{r component-analysis}
cat("=== COMPONENT ANALYSIS ===\n")

# Analyze weakly connected components
weak_components <- components(graph_connected, mode = "weak")
cat("Number of weakly connected components:", weak_components$no, "\n")
cat("Size of largest weak component:", max(weak_components$csize), "\n")
cat("Proportion of nodes in largest weak component:", 
    round(max(weak_components$csize) / vcount(graph_connected) * 100, 2), "%\n\n")

# Analyze strongly connected components
strong_components <- components(graph_connected, mode = "strong")
cat("Number of strongly connected components:", strong_components$no, "\n")
cat("Size of largest strong component:", max(strong_components$csize), "\n")
cat("Proportion of nodes in largest strong component:", 
    round(max(strong_components$csize) / vcount(graph_connected) * 100, 2), "%\n\n")

# Component size distribution
cat("Weak component sizes (top 10):\n")
weak_sizes <- sort(weak_components$csize, decreasing = TRUE)
print(head(weak_sizes, 10))

cat("\nStrong component sizes (top 10):\n")
strong_sizes <- sort(strong_components$csize, decreasing = TRUE)
print(head(strong_sizes, 10))
```

```{r degree-distribution-analysis}
# Create comprehensive degree distribution analysis

# Prepare data for plotting
degree_data <- data.frame(
  node_id = V(graph_connected)$name,
  total_degree = all_degrees,
  in_degree = in_degrees,
  out_degree = out_degrees
)

# Add node attributes for additional analysis
degree_data$institution <- V(graph_connected)$institution
degree_data$subtopic <- V(graph_connected)$subtopic
degree_data$year <- V(graph_connected)$year
degree_data$citations <- V(graph_connected)$citations

cat("=== DEGREE DISTRIBUTION SUMMARY ===\n")
cat("Total degree quartiles:\n")
print(quantile(all_degrees))
cat("\nIn-degree quartiles:\n")
print(quantile(in_degrees))
cat("\nOut-degree quartiles:\n")
print(quantile(out_degrees))
```

```{r in-degree-histogram}
# In-degree distribution histogram
ggplot(degree_data, aes(x = in_degree)) +
  geom_histogram(binwidth = 1, fill = "lightblue", alpha = 0.7, color = "white") +
  labs(title = "In-Degree Distribution (Citations Received)",
       subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
       x = "In-Degree (Citations Received)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(in_degrees), by = 5))

# Print summary statistics
cat("\nIN-DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(in_degrees), 2), "\n")
cat("Median:", median(in_degrees), "\n")
cat("Mode:", names(sort(table(in_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with 0 in-degree:", sum(in_degrees == 0), "\n")
cat("Nodes with >10 in-degree:", sum(in_degrees > 10), "\n")
```

```{r out-degree-histogram}
# Out-degree distribution histogram
ggplot(degree_data, aes(x = out_degree)) +
  geom_histogram(binwidth = 1, fill = "lightcoral", alpha = 0.7, color = "white") +
  labs(title = "Out-Degree Distribution (Citations Made)",
       subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
       x = "Out-Degree (Citations Made)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(out_degrees), by = 5))

# Print summary statistics
cat("\nOUT-DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(out_degrees), 2), "\n")
cat("Median:", median(out_degrees), "\n")
cat("Mode:", names(sort(table(out_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with 0 out-degree:", sum(out_degrees == 0), "\n")
cat("Nodes with >10 out-degree:", sum(out_degrees > 10), "\n")
```

```{r total-degree-histogram}
# Total degree distribution histogram
ggplot(degree_data, aes(x = total_degree)) +
  geom_histogram(binwidth = 2, fill = "lightgreen", alpha = 0.7, color = "white") +
  labs(title = "Total Degree Distribution",
       subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
       x = "Total Degree (In + Out)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(all_degrees), by = 10))

# Print summary statistics
cat("\nTOTAL DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(all_degrees), 2), "\n")
cat("Median:", median(all_degrees), "\n")
cat("Mode:", names(sort(table(all_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with degree 1:", sum(all_degrees == 1), "\n")
cat("Nodes with degree >20:", sum(all_degrees > 20), "\n")
```

```{r degree-comparison-plot}
# Create combined degree distribution plot
degree_long <- reshape2::melt(degree_data[, c("in_degree", "out_degree", "total_degree")],
                             variable.name = "degree_type",
                             value.name = "degree_value")

# Rename for better labels
degree_long$degree_type <- factor(degree_long$degree_type,
                                 levels = c("in_degree", "out_degree", "total_degree"),
                                 labels = c("In-Degree", "Out-Degree", "Total Degree"))

# Create faceted histogram
ggplot(degree_long, aes(x = degree_value, fill = degree_type)) +
  geom_histogram(alpha = 0.7, color = "white", bins = 30) +
  facet_wrap(~degree_type, scales = "free") +
  scale_fill_manual(values = c("In-Degree" = "lightblue", 
                              "Out-Degree" = "lightcoral", 
                              "Total Degree" = "lightgreen")) +
  labs(title = "Degree Distribution Comparison",
       subtitle = "In-Degree vs Out-Degree vs Total Degree",
       x = "Degree Value",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.position = "none",
        strip.text = element_text(face = "bold"))
```

```{r largest-component-analysis}
# Analyze the largest component in detail
cat("=== LARGEST COMPONENT DETAILED ANALYSIS ===\n")

# Extract the largest weakly connected component
largest_comp_nodes <- which(weak_components$membership == which.max(weak_components$csize))
largest_component <- induced_subgraph(graph_connected, largest_comp_nodes)

cat("Largest component statistics:\n")
cat("Nodes:", vcount(largest_component), "\n")
cat("Edges:", ecount(largest_component), "\n")
cat("Density:", round(edge_density(largest_component), 6), "\n")
cat("Average in degree:", round(mean(degree(largest_component, mode = "in")), 2), "\n")
cat("Average out degree:", round(mean(degree(largest_component, mode = "out")), 2), "\n")
cat("Average degree:", round(mean(degree(largest_component, mode = "all")), 2), "\n")
cat("Diameter:", diameter(largest_component, directed = FALSE), "\n")
cat("Average path length:", round(mean_distance(largest_component, directed = FALSE), 2), "\n\n")

# Check if there are smaller components worth analyzing
if(length(unique(weak_components$csize)) > 1) {
  second_largest_size <- sort(weak_components$csize, decreasing = TRUE)[2]
  cat("Second largest component size:", second_largest_size, "\n")
  cat("Ratio (largest/second largest):", round(max(weak_components$csize) / 
  second_largest_size, 2), "\n")
}
```

## Advanced Analysis of Largest Component (Jinxi Hu)

```{r centrality-analysis}
cat("=== CENTRALITY ANALYSIS OF LARGEST COMPONENT ===\n")

# Calculate various centrality measures
cat("Calculating centrality measures...\n")

# Degree centrality (already calculated above)
degree_cent_in <- degree(largest_component, mode = "in", normalized = TRUE)
degree_cent_out <- degree(largest_component, mode = "out", normalized = TRUE)
degree_cent_all <- degree(largest_component, mode = "all", normalized = TRUE)

# Betweenness centrality
betweenness_cent <- betweenness(largest_component, directed = TRUE, normalized = TRUE)

# Closeness centrality
closeness_cent_in <- closeness(largest_component, mode = "in", normalized = TRUE)
closeness_cent_out <- closeness(largest_component, mode = "out", normalized = TRUE)

# Eigenvector centrality
eigenvector_cent <- eigen_centrality(largest_component, directed = TRUE, scale = TRUE)$vector

# PageRank centrality
pagerank_cent <- page_rank(largest_component, directed = TRUE)$vector

# Authority and Hub scores (HITS algorithm)
hits_scores <- hub_score(largest_component)
hub_cent <- hits_scores$vector
authority_cent <- authority_score(largest_component)$vector

cat("All centrality measures calculated successfully!\n\n")

# Create centrality summary
centrality_summary <- data.frame(
  node_id = V(largest_component)$name,
  degree_in = degree_cent_in,
  degree_out = degree_cent_out,
  degree_all = degree_cent_all,
  betweenness = betweenness_cent,
  closeness_in = closeness_cent_in,
  closeness_out = closeness_cent_out,
  eigenvector = eigenvector_cent,
  pagerank = pagerank_cent,
  hub = hub_cent,
  authority = authority_cent
)
# Print top nodes by different centrality measures
cat("TOP 5 NODES BY DIFFERENT CENTRALITY MEASURES:\n\n")

cat("Highest In-Degree Centrality (most cited):\n")
top_in_degree <- centrality_summary[order(centrality_summary$degree_in, decreasing = TRUE)[1:5], 
                                   c("node_id", "degree_in")]
print(top_in_degree)

cat("\nHighest PageRank (most influential):\n")
top_pagerank <- centrality_summary[order(centrality_summary$pagerank, decreasing = TRUE)[1:5], 
                                  c("node_id", "pagerank")]
print(top_pagerank)

cat("\nHighest Betweenness Centrality (most important bridges):\n")
top_betweenness <- centrality_summary[order(centrality_summary$betweenness, decreasing = TRUE)[1:5], 
                                     c("node_id", "betweenness")]
print(top_betweenness)

cat("\nHighest Authority Score (most authoritative):\n")
top_authority <- centrality_summary[order(centrality_summary$authority, decreasing = TRUE)[1:5], 
                                   c("node_id", "authority")]
print(top_authority)
```

```{r node-betweenness-analysis}
cat("=== NODE BETWEENNESS DETAILED ANALYSIS ===\n")

# Detailed betweenness analysis
betweenness_stats <- summary(betweenness_cent)
cat("Betweenness centrality statistics:\n")
print(betweenness_stats)

cat("\nNodes with highest betweenness (potential bridges):\n")
high_betweenness_threshold <- quantile(betweenness_cent, 0.95)
high_betweenness_nodes <- which(betweenness_cent >= high_betweenness_threshold)
cat("Number of high betweenness nodes (top 5%):", length(high_betweenness_nodes), "\n")

# Create betweenness distribution plot
betweenness_df <- data.frame(
  node_id = V(largest_component)$name,
  betweenness = betweenness_cent,
  institution = V(largest_component)$institution,
  subtopic = V(largest_component)$subtopic
)

# Betweenness distribution histogram
ggplot(betweenness_df, aes(x = betweenness)) +
  geom_histogram(bins = 30, fill = "purple", alpha = 0.7, color = "white") +
  labs(title = "Node Betweenness Centrality Distribution",
       subtitle = "Distribution of bridging importance in largest component",
       x = "Normalized Betweenness Centrality",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# Identify top bridging papers
cat("\nTop 10 bridging papers (highest betweenness):\n")
top_bridges <- betweenness_df[order(betweenness_df$betweenness, decreasing = TRUE)[1:10], ]
print(top_bridges[, c("node_id", "betweenness", "subtopic", "institution")])
```

```{r edge-betweenness-analysis}
cat("\n=== EDGE BETWEENNESS ANALYSIS ===\n")

# Calculate edge betweenness
cat("Calculating edge betweenness (this may take a moment)...\n")
edge_betweenness <- edge_betweenness(largest_component, directed = TRUE)

cat("Edge betweenness calculation completed!\n")
cat("Number of edges analyzed:", length(edge_betweenness), "\n")

# Edge betweenness statistics
edge_bet_stats <- summary(edge_betweenness)
cat("\nEdge betweenness statistics:\n")
print(edge_bet_stats)

# Find edges with highest betweenness
top_edge_indices <- order(edge_betweenness, decreasing = TRUE)[1:10]
top_edges <- get.edges(largest_component, top_edge_indices)

cat("\nTop 10 edges by betweenness (most critical connections):\n")
for(i in 1:10) {
  edge_idx <- top_edge_indices[i]
  from_node <- V(largest_component)$name[top_edges[i, 1]]
  to_node <- V(largest_component)$name[top_edges[i, 2]]
  bet_value <- round(edge_betweenness[edge_idx], 4)
  cat(sprintf("%d. %s -> %s (betweenness: %.4f)\n", i, from_node, to_node, bet_value))
}

# Edge betweenness distribution plot
edge_bet_df <- data.frame(edge_betweenness = edge_betweenness)
ggplot(edge_bet_df, aes(x = edge_betweenness)) +
  geom_histogram(bins = 50, fill = "orange", alpha = 0.7, color = "white") +
  labs(title = "Edge Betweenness Distribution",
       subtitle = "Distribution of edge importance as bridges in largest component",
       x = "Edge Betweenness",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

```{r community-detection-method1}
cat("\n=== COMMUNITY DETECTION - METHOD 1: LOUVAIN ALGORITHM ===\n")

# Method 1: Louvain algorithm (modularity optimization)
cat("Running Louvain algorithm for community detection...\n")

# Convert to undirected for community detection
largest_component_undirected <- as.undirected(largest_component, mode = "collapse")

# Louvain algorithm
louvain_communities <- cluster_louvain(largest_component_undirected)

cat("Louvain algorithm completed!\n")
cat("Number of communities found:", length(louvain_communities), "\n")
cat("Modularity score:", round(modularity(louvain_communities), 4), "\n")

# Community size distribution
louvain_sizes <- sizes(louvain_communities)
cat("\nCommunity sizes:\n")
print(sort(louvain_sizes, decreasing = TRUE))

cat("\nLargest 5 communities:\n")
large_communities <- sort(louvain_sizes, decreasing = TRUE)[1:5]
print(large_communities)

# Create community membership dataframe
louvain_membership <- data.frame(
  node_id = V(largest_component_undirected)$name,
  community = membership(louvain_communities),
  institution = V(largest_component_undirected)$institution,
  subtopic = V(largest_component_undirected)$subtopic
)

# Analyze community composition by subtopic
cat("\nCommunity composition analysis:\n")
for(i in 1:min(5, length(louvain_communities))) {
  cat(sprintf("\nCommunity %d (size: %d):\n", i, louvain_sizes[i]))
  community_nodes <- louvain_membership[louvain_membership$community == i, ]
  subtopic_dist <- table(community_nodes$subtopic)
  cat("Main subtopics:\n")
  print(sort(subtopic_dist, decreasing = TRUE)[1:min(3, length(subtopic_dist))])
}
```

```{r community-detection-method2}
cat("\n=== COMMUNITY DETECTION - METHOD 2: EDGE BETWEENNESS ===\n")

# Method 2: Edge betweenness-based community detection
cat("Running edge betweenness community detection...\n")

# This method removes edges with highest betweenness iteratively
edge_betweenness_communities <- cluster_edge_betweenness(largest_component_undirected, directed = FALSE)

cat("Edge betweenness algorithm completed!\n")
cat("Number of communities found:", length(edge_betweenness_communities), "\n")
cat("Modularity score:", round(modularity(edge_betweenness_communities), 4), "\n")

# Community size distribution
eb_sizes <- sizes(edge_betweenness_communities)
cat("\nCommunity sizes:\n")
print(sort(eb_sizes, decreasing = TRUE))

# Compare the two methods
cat("\n=== COMPARISON OF COMMUNITY DETECTION METHODS ===\n")
cat("Louvain - Communities:", length(louvain_communities), 
    "| Modularity:", round(modularity(louvain_communities), 4), "\n")
cat("Edge Betweenness - Communities:", length(edge_betweenness_communities), 
    "| Modularity:", round(modularity(edge_betweenness_communities), 4), "\n")

# Create comparison plot
community_comparison <- data.frame(
  Method = c("Louvain", "Edge Betweenness"),
  Communities = c(length(louvain_communities), length(edge_betweenness_communities)),
  Modularity = c(modularity(louvain_communities), modularity(edge_betweenness_communities))
)

# Plot comparison
p1 <- ggplot(community_comparison, aes(x = Method, y = Communities, fill = Method)) +
  geom_bar(stat = "identity", alpha = 0.7) +
  scale_fill_manual(values = c("Louvain" = "lightblue", 
                               "Edge Betweenness" = "lightcoral")) +
  labs(title = "Number of Communities",
       y = "Number of Communities") +
  theme_minimal() +
  theme(legend.position = "none")

p2 <- ggplot(community_comparison, aes(x = Method, y = Modularity, fill = Method)) +
  geom_bar(stat = "identity", alpha = 0.7) +
  scale_fill_manual(values = c("Louvain" = "lightblue", 
                               "Edge Betweenness" = "lightcoral")) +
  labs(title = "Modularity Score",
       y = "Modularity") +
  theme_minimal() +
  theme(legend.position = "none")

# Display plots side by side
grid.arrange(p1, p2, ncol = 2, 
             top = "Community Detection Methods Comparison")
```

## Community Structure on Full Directed Graph (Louvain + Infomap)

```{r community-full-directed}
cat("\n=== COMMUNITY STRUCTURE ON FULL DIRECTED GRAPH ===\n")

# Use the full connected directed graph
graph_dir <- graph_connected
graph_undir <- as.undirected(graph_dir, mode = "collapse")

# Louvain (on undirected projection) and Infomap (directed)
louvain_full <- cluster_louvain(graph_undir)
infomap_full <- cluster_infomap(graph_dir)

cat("Louvain communities:", length(louvain_full), 
    "| Modularity:", round(modularity(louvain_full), 4), "\n")
cat("Infomap communities:", length(infomap_full), 
    "| Codelength:", round(infomap_full$codelength, 4), "\n\n")

cat("Top 10 Louvain community sizes:\n")
print(head(sort(sizes(louvain_full), decreasing = TRUE), 10))
cat("\nTop 10 Infomap community sizes:\n")
print(head(sort(sizes(infomap_full), decreasing = TRUE), 10))
```

```{r community-assortativity-heatmap}
cat("\n=== MIXING AND ASSORTATIVITY (DIRECTED) ===\n")

# Build membership dataframe for downstream analysis
community_df <- data.frame(
  node_id = V(graph_dir)$name,
  institution = V(graph_dir)$institution,
  subtopic = V(graph_dir)$subtopic,
  louvain = membership(louvain_full),
  infomap = membership(infomap_full)
)

# Assortativity by institution and subtopic on directed graph
inst_factor <- as.factor(community_df$institution)
subtopic_factor <- as.factor(community_df$subtopic)

assort_inst <- assortativity_nominal(graph_dir, inst_factor, directed = TRUE)
assort_subtopic <- assortativity_nominal(graph_dir, subtopic_factor, directed = TRUE)

cat("Assortativity (institution):", round(assort_inst, 3), "\n")
cat("Assortativity (subtopic):", round(assort_subtopic, 3), "\n\n")

# Heatmaps: community vs institution/subtopic (Louvain membership)
cat("Building heatmaps for Louvain communities vs institution/subtopic...\n")

# Limit categories for readability
top_inst <- names(sort(table(community_df$institution), decreasing = TRUE))[1:min(15, length(unique(community_df$institution)))]
top_subtopic <- names(sort(table(community_df$subtopic), decreasing = TRUE))[1:min(15, length(unique(community_df$subtopic)))]

# Community ordering by size
comm_order <- names(sort(sizes(louvain_full), decreasing = TRUE))

# Institution heatmap (row-normalized to show composition per community)
inst_table <- table(community_df$louvain, factor(community_df$institution, levels = top_inst))
inst_prop <- prop.table(inst_table, 1)
inst_melt <- melt(inst_prop)
inst_melt$Community <- factor(inst_melt$Var1, levels = comm_order)
inst_melt$Institution <- inst_melt$Var2

ggplot(inst_melt, aes(x = Institution, y = Community, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue", name = "Share") +
  labs(title = "Louvain Community Composition by Institution",
       x = "Institution (Top 15 by count)", y = "Community (size-ranked)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))

# Subtopic heatmap (row-normalized to show composition per community)
subtopic_table <- table(community_df$louvain, factor(community_df$subtopic, levels = top_subtopic))
subtopic_prop <- prop.table(subtopic_table, 1)
subtopic_melt <- melt(subtopic_prop)
subtopic_melt$Community <- factor(subtopic_melt$Var1, levels = comm_order)
subtopic_melt$Subtopic <- subtopic_melt$Var2

ggplot(subtopic_melt, aes(x = Subtopic, y = Community, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "darkorange", name = "Share") +
  labs(title = "Louvain Community Composition by Subtopic",
       x = "Subtopic (Top 15 by count)", y = "Community (size-ranked)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```

## k-core Decomposition and Network Robustness

```{r kcore-decomposition}
cat("\n=== K-CORE DECOMPOSITION (CONNECTED DIRECTED GRAPH) ===\n")

# Use existing core column if present, otherwise compute
nodes_core_full <- read.csv("data/nodes_core_full.csv")
if (!"core" %in% names(nodes_core_full)) {
  V(graph_connected)$core <- coreness(graph_connected, mode = "all")
} else {
  core_map <- setNames(nodes_core_full$core, nodes_core_full$local_id)
  V(graph_connected)$core <- core_map[V(graph_connected)$name]
}

core_scores <- V(graph_connected)$core
cat("Max k-core level:", max(core_scores, na.rm = TRUE), "\n")
cat("Node counts per k:\n")
print(sort(table(core_scores), decreasing = TRUE))

# Distribution bar plot
core_df <- data.frame(core = core_scores)
ggplot(core_df, aes(x = core)) +
  geom_bar(fill = "steelblue", alpha = 0.8, color = "white") +
  labs(title = "k-core Distribution (connected directed graph)",
       x = "k-core level", y = "Node count") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Highest core set
top_k <- max(core_scores, na.rm = TRUE)
top_core_nodes <- V(graph_connected)[core_scores == top_k]
cat("\nTop core (k =", top_k, ") node count:", length(top_core_nodes), "\n")
```

```{r robustness-simulation}
cat("\n=== NETWORK ROBUSTNESS SIMULATION: NODE REMOVAL ===\n")

graph_dir_orig <- graph_connected
v_total <- vcount(graph_dir_orig)
fractions <- seq(0, 0.9, by = 0.1)  # removal fraction

compute_metrics <- function(g, v0) {
  if (vcount(g) == 0) return(c(giant_frac = 0, eff = 0))
  comps <- components(g, mode = "weak")
  giant_frac <- max(comps$csize) / v0
  avg_dist <- suppressWarnings(mean_distance(g, directed = FALSE, unconnected = TRUE))
  eff <- if (is.finite(avg_dist) && avg_dist > 0) 1 / avg_dist else 0
  c(giant_frac = giant_frac, eff = eff)
}

run_sim <- function(order_vec, label) {
  res <- data.frame()
  for (f in fractions) {
    remove_n <- floor(f * v_total)
    keep_nodes <- V(graph_dir_orig)$name
    if (remove_n > 0) keep_nodes <- keep_nodes[-order_vec[1:remove_n]]
    g_sub <- induced_subgraph(graph_dir_orig, keep_nodes)
    metrics <- compute_metrics(g_sub, v_total)
    res <- rbind(res, data.frame(strategy = label,
                                 removed_frac = f,
                                 giant_frac = metrics["giant_frac"],
                                   efficiency = metrics["eff"]))
  }
  res
}

# Removal orders
deg_order <- order(degree(graph_dir_orig, mode = "all"), decreasing = TRUE)
pr_order <- order(page_rank(graph_dir_orig)$vector, decreasing = TRUE)
rand_order <- sample(v_total)

sim_results <- rbind(
  run_sim(deg_order, "By Degree"),
  run_sim(pr_order, "By PageRank"),
  run_sim(rand_order, "Random")
)

ggplot(sim_results, aes(x = removed_frac, y = giant_frac, color = strategy)) +
  geom_line(size = 1) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = "Giant Weak Component Under Node Removal",
       x = "Removed nodes (fraction)", y = "Largest component fraction",
       color = "Removal strategy") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

ggplot(sim_results, aes(x = removed_frac, y = efficiency, color = strategy)) +
  geom_line(size = 1) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(title = "Network Efficiency Under Node Removal (1 / mean shortest path)",
       x = "Removed nodes (fraction)", y = "Efficiency metric",
       color = "Removal strategy") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r centrality-correlation-analysis}
cat("\n=== CENTRALITY MEASURES CORRELATION ANALYSIS ===\n")

# Analyze correlations between different centrality measures
centrality_cor_data <- centrality_summary[, 
                              c("degree_in", "degree_out", "betweenness", 
                                "closeness_in", "closeness_out", 
                                "eigenvector", "pagerank", "authority", "hub")]

# Calculate correlation matrix
cor_matrix <- cor(centrality_cor_data, use = "complete.obs")
cat("Correlation matrix calculated\n")
print(round(cor_matrix, 3))

# Create correlation heatmap
cor_melted <- melt(cor_matrix)
ggplot(cor_melted, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                      midpoint = 0, limit = c(-1,1), space = "Lab",
                      name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        plot.title = element_text(hjust = 0.5)) +
  labs(title = "Centrality Measures Correlation Matrix",
       x = "", y = "") +
  geom_text(aes(label = round(value, 2)), size = 3)
```

## Largest Component Visualization (Jinxi Hu)

```{r largest-component-basic-plot}
cat("=== LARGEST COMPONENT VISUALIZATION ===\n")

# Basic layout for consistent visualization across all plots
cat("Calculating network layout (this may take a moment)...\n")
layout_large <- layout_with_fr(largest_component, 
                              weights = NULL, 
                              niter = 1000, 
                              start.temp = sqrt(vcount(largest_component)))

cat("Layout calculation completed!\n")
cat("Plotting largest component with different color schemes...\n\n")

# Basic plot with default colors
plot(largest_component, 
     layout = layout_large,
     vertex.size = 4, 
     vertex.label = NA,
     edge.arrow.size = 0.3,
     edge.width = 0.5,
     edge.color = "gray70",
     vertex.color = "lightblue",
     vertex.frame.color = "white",
     main = "Largest Component - Basic View",
     sub = paste("Nodes:", vcount(largest_component), 
                "| Edges:", ecount(largest_component)))
```

```{r largest-component-by-subtopic}
# Plot colored by research subtopic
cat("1. VISUALIZATION BY RESEARCH SUBTOPIC\n")

# Get unique subtopics and create color palette
subtopics_large <- V(largest_component)$subtopic
unique_subtopics <- unique(subtopics_large)
n_subtopics <- length(unique_subtopics)

cat("Number of unique subtopics in largest component:", n_subtopics, "\n")

# Create color palette for subtopics
if(n_subtopics <= 12) {
  colors_subtopic <- RColorBrewer::brewer.pal(max(3, n_subtopics), "Set3")
} else {
  # For more than 12 subtopics, use rainbow colors
  colors_subtopic <- rainbow(n_subtopics)
}

# Create named color vector to ensure consistent mapping
names(colors_subtopic) <- unique_subtopics

# Assign colors to nodes using the named vector
vertex_colors_subtopic <- colors_subtopic[subtopics_large]

# Plot by subtopic
plot(largest_component, 
     layout = layout_large,
     vertex.size = 4, 
     vertex.label = NA,
     edge.arrow.size = 0.3,
     edge.width = 0.5,
     edge.color = "gray70",
     vertex.color = vertex_colors_subtopic,
     vertex.frame.color = "white",
     main = "Largest Component - Colored by Research Subtopic",
     sub = paste("Nodes:", vcount(largest_component), 
                "| Subtopics:", n_subtopics))

# Add legend for subtopics (show top 10 only if too many)
if(n_subtopics > 10) {
  # Show only the most frequent subtopics
  top_subtopics <- names(sort(table(subtopics_large), decreasing = TRUE))[1:10]
  legend_subtopics <- c(top_subtopics, "Others...")
  legend_colors <- c(colors_subtopic[top_subtopics], "gray")
} else {
  legend_subtopics <- unique_subtopics
  legend_colors <- colors_subtopic[unique_subtopics]
}

legend("topright", 
       legend = legend_subtopics,
       fill = legend_colors,
       cex = 0.6,
       title = "Research Subtopic",
       bg = "white")

# Print subtopic distribution
cat("\nSubtopic distribution in largest component:\n")
subtopic_dist <- sort(table(subtopics_large), decreasing = TRUE)
print(head(subtopic_dist, 10))
```

```{r largest-component-by-institution}
# Plot colored by institution
cat("\n2. VISUALIZATION BY INSTITUTION\n")

# Get unique institutions and create color palette
institutions_large <- V(largest_component)$institution
unique_institutions <- unique(institutions_large)
n_institutions <- length(unique_institutions)

cat("Number of unique institutions in largest component:", n_institutions, "\n")

# Get top 10 institutions by frequency first
institution_counts <- sort(table(institutions_large), decreasing = TRUE)
if(n_institutions > 10) {
  top_institutions <- names(institution_counts)[1:10]
} else {
  top_institutions <- names(institution_counts)
}

# Create color palette for institutions with better differentiation
if(length(top_institutions) <= 12) {
  # Use highly contrasting colors with maximum visual separation
  colors_for_top <- c("#FF0000", "#0000FF", "#00AA00", "#FF8000", "#8000FF", 
                     "#00CCCC", "#FF1493", "#32CD32", "#FFD700", "#8B4513", 
                     "#FF69B4", "#4169E1")
  colors_top_institutions <- colors_for_top[1:length(top_institutions)]
  names(colors_top_institutions) <- top_institutions
} else {
  # For more than 12 institutions, use diverse colors with better spacing
  colors_top_institutions <- rainbow(length(top_institutions), s = 1, v = 0.8)
  names(colors_top_institutions) <- top_institutions
}

# Assign colors to nodes
vertex_colors_display <- rep("gray", length(institutions_large))
for(i in 1:length(institutions_large)) {
  if(institutions_large[i] %in% top_institutions) {
    vertex_colors_display[i] <- colors_top_institutions[institutions_large[i]]
  }
}

# Plot by institution
plot(largest_component, 
     layout = layout_large,
     vertex.size = 4, 
     vertex.label = NA,
     edge.arrow.size = 0.3,
     edge.width = 0.5,
     edge.color = "gray70",
     vertex.color = vertex_colors_display,
     vertex.frame.color = "white",
     main = "Largest Component - Colored by Institution",
     sub = paste("Nodes:", vcount(largest_component), 
                "| Institutions:", n_institutions))

# Add legend for institutions
if(n_institutions > 10) {
  legend_institutions <- c(top_institutions, "Others...")
  legend_colors_inst <- c(colors_top_institutions[top_institutions], "gray")
} else {
  legend_institutions <- top_institutions
  legend_colors_inst <- colors_top_institutions[top_institutions]
}

legend("topright", 
       legend = legend_institutions,
       fill = legend_colors_inst,
       cex = 0.6,
       title = "Institution",
       bg = "white")

# Print institution distribution
cat("\nInstitution distribution in largest component:\n")
institution_dist <- sort(table(institutions_large), decreasing = TRUE)
print(head(institution_dist, 10))
```

```{r largest-component-by-community}
# Plot colored by Louvain communities
cat("\n3. VISUALIZATION BY LOUVAIN COMMUNITIES\n")

# Get community membership (already calculated in previous chunk)
community_membership <- membership(louvain_communities)
n_communities <- length(louvain_communities)

cat("Number of Louvain communities:", n_communities, "\n")
cat("Modularity score:", round(modularity(louvain_communities), 4), "\n")

# Create color palette for communities
if(n_communities <= 12) {
  colors_community <- RColorBrewer::brewer.pal(max(3, n_communities), "Set1")
} else {
  colors_community <- rainbow(n_communities)
}

# Assign colors to nodes based on community membership
vertex_colors_community <- colors_community[community_membership]

# Plot by community
plot(largest_component_undirected,  # Use undirected version for community plot
     layout = layout_large,
     vertex.size = 4, 
     vertex.label = NA,
     edge.width = 0.5,
     edge.color = "gray70",
     vertex.color = vertex_colors_community,
     vertex.frame.color = "white",
     main = "Largest Component - Colored by Louvain Communities",
     sub = paste("Nodes:", vcount(largest_component), 
                "| Communities:", n_communities, 
                "| Modularity:", round(modularity(louvain_communities), 3)))

# Add legend for communities
legend("topright", 
       legend = paste("Community", 1:min(n_communities, 10)),
       fill = colors_community[1:min(n_communities, 10)],
       cex = 0.6,
       title = "Louvain Community",
       bg = "white")

# Print community size distribution
cat("\nCommunity size distribution:\n")
community_sizes <- sort(sizes(louvain_communities), decreasing = TRUE)
print(community_sizes)
```

```{r largest-component-weighted-by-centrality}
# Plot with node sizes representing centrality measures
cat("\n4. VISUALIZATION WITH CENTRALITY-WEIGHTED NODE SIZES\n")

# Use PageRank centrality for node sizes
pagerank_values <- page_rank(largest_component, directed = TRUE)$vector
# Scale node sizes appropriately (between 2 and 15)
node_sizes <- 2 + 13 * (pagerank_values - min(pagerank_values)) / 
              (max(pagerank_values) - min(pagerank_values))

# Plot with PageRank-weighted sizes and community colors
plot(largest_component, 
     layout = layout_large,
     vertex.size = node_sizes, 
     vertex.label = NA,
     edge.arrow.size = 0.3,
     edge.width = 0.5,
     edge.color = "gray70",
     vertex.color = vertex_colors_community,
     vertex.frame.color = "white",
     main = "Largest Component - Communities with PageRank-weighted Sizes",
     sub = paste("Node size âˆ PageRank centrality | Communities by Louvain algorithm"))

# Add legends
legend("topleft", 
       legend = c("Smallest PageRank", "Largest PageRank"),
       pch = 21,
       pt.cex = c(0.5, 2),
       pt.bg = "lightblue",
       title = "Node Size",
       bg = "white",
       cex = 0.8)

legend("topright", 
       legend = paste("Community", 1:min(n_communities, 8)),
       fill = colors_community[1:min(n_communities, 8)],
       cex = 0.6,
       title = "Louvain Community",
       bg = "white")

# Print top PageRank nodes
cat("\nTop 10 nodes by PageRank centrality:\n")
top_pagerank_nodes <- order(pagerank_values, decreasing = TRUE)[1:10]
pagerank_summary <- data.frame(
  node_id = V(largest_component)$name[top_pagerank_nodes],
  pagerank = round(pagerank_values[top_pagerank_nodes], 4),
  community = community_membership[top_pagerank_nodes],
  subtopic = V(largest_component)$subtopic[top_pagerank_nodes],
  institution = V(largest_component)$institution[top_pagerank_nodes]
)
print(pagerank_summary)
```

```{r component-analysis-summary}
cat("\n=== LARGEST COMPONENT ANALYSIS SUMMARY ===\n")

# Summary statistics
cat("STRUCTURAL PROPERTIES:\n")
cat("- Nodes:", vcount(largest_component), "\n")
cat("- Edges:", ecount(largest_component), "\n")
cat("- Density:", round(edge_density(largest_component), 6), "\n")
cat("- Average clustering coefficient:", round(transitivity(largest_component, type = "average"), 4), "\n")
cat("- Diameter:", diameter(largest_component, directed = FALSE), "\n")
cat("- Average path length:", round(mean_distance(largest_component, directed = FALSE), 2), "\n\n")

cat("DIVERSITY MEASURES:\n")
cat("- Research subtopics:", length(unique(subtopics_large)), "\n")
cat("- Institutions:", length(unique(institutions_large)), "\n")
cat("- Louvain communities:", n_communities, "\n")
cat("- Community modularity:", round(modularity(louvain_communities), 4), "\n\n")

cat("CENTRALITY HIGHLIGHTS:\n")
cat("- Highest PageRank node:", V(largest_component)$name[which.max(pagerank_values)], 
    "(", round(max(pagerank_values), 4), ")\n")
cat("- Highest betweenness node:", V(largest_component)$name[which.max(betweenness_cent)], 
    "(", round(max(betweenness_cent), 4), ")\n")
cat("- Most cited node (in-degree):", V(largest_component)$name[which.max(degree_cent_in)], 
    "(", max(degree(largest_component, mode = "in")), " citations)\n")
```
