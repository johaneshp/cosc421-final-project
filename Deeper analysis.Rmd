---
title: "Deeper analysis and Network statistics"
author: "Jinxi_Hu-48528608, Samarth_Grover-38220463"
date: "2025-11-09"
output: 
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## set up
```{r set up,message = FALSE, warning = FALSE}
library(readr)
library(igraph)
library(RColorBrewer)
library(ggplot2)
library(reshape2)
library(scales)
library(gridExtra)
set.seed(48528608)
```

## Load and prepare connected nodes data (Jinxi Hu)

```{r load-connected-data}
# Load the connected nodes and edges data
nodes_connected <- read.csv("data/nodes_connected.csv")
edges_connected <- read.csv("data/edges_connected.csv")

cat("=== DATA LOADING ===\n")
cat("Connected nodes loaded:", nrow(nodes_connected), "\n")
cat("Connected edges loaded:", nrow(edges_connected), "\n\n")

# Create the graph from connected nodes only
graph_connected <- graph_from_data_frame(edges_connected, 
                                        vertices = nodes_connected, 
                                        directed = TRUE)
# Remove multiple edges and self-loops for cleaner analysis
graph_connected <- simplify(graph_connected, 
                          remove.multiple = TRUE, 
                          remove.loops = TRUE)

cat("Graph created successfully\n")
cat("Final nodes in graph:", vcount(graph_connected), "\n")
cat("Final edges in graph:", ecount(graph_connected), "\n\n")
```

## Basic Graph Analysis (Jinxi Hu)

```{r basic-graph-analysis}
cat("=== BASIC GRAPH STATISTICS ===\n")
cat("Total nodes:", vcount(graph_connected), "\n")
cat("Total edges (citations):", ecount(graph_connected), "\n")
cat("Network density:", round(edge_density(graph_connected), 6), "\n")
cat("Is directed:", is_directed(graph_connected), "\n")
cat("Is weighted:", is_weighted(graph_connected), "\n\n")

# Calculate degree statistics
all_degrees <- degree(graph_connected, mode = "all")
in_degrees <- degree(graph_connected, mode = "in")
out_degrees <- degree(graph_connected, mode = "out")

cat("=== DEGREE STATISTICS ===\n")
cat("Average total degree:", round(mean(all_degrees), 2), "\n")
cat("Average in-degree (citations received):", round(mean(in_degrees), 2), "\n")
cat("Average out-degree (citations made):", round(mean(out_degrees), 2), "\n\n")

cat("Degree range (total):", min(all_degrees), "-", max(all_degrees), "\n")
cat("Degree range (in):", min(in_degrees), "-", max(in_degrees), "\n")
cat("Degree range (out):", min(out_degrees), "-", max(out_degrees), "\n\n")

cat("Standard deviation (total):", round(sd(all_degrees), 2), "\n")
cat("Standard deviation (in):", round(sd(in_degrees), 2), "\n")
cat("Standard deviation (out):", round(sd(out_degrees), 2), "\n\n")
```

```{r component-analysis}
cat("=== COMPONENT ANALYSIS ===\n")

# Analyze weakly connected components
weak_components <- components(graph_connected, mode = "weak")
cat("Number of weakly connected components:", weak_components$no, "\n")
cat("Size of largest weak component:", max(weak_components$csize), "\n")
cat("Proportion of nodes in largest weak component:", 
    round(max(weak_components$csize) / vcount(graph_connected) * 100, 2), "%\n\n")

# Analyze strongly connected components
strong_components <- components(graph_connected, mode = "strong")
cat("Number of strongly connected components:", strong_components$no, "\n")
cat("Size of largest strong component:", max(strong_components$csize), "\n")
cat("Proportion of nodes in largest strong component:", 
    round(max(strong_components$csize) / vcount(graph_connected) * 100, 2), "%\n\n")

# Component size distribution
cat("Weak component sizes (top 10):\n")
weak_sizes <- sort(weak_components$csize, decreasing = TRUE)
print(head(weak_sizes, 10))

cat("\nStrong component sizes (top 10):\n")
strong_sizes <- sort(strong_components$csize, decreasing = TRUE)
print(head(strong_sizes, 10))
```

```{r degree-distribution-analysis}
# Create comprehensive degree distribution analysis

# Prepare data for plotting
degree_data <- data.frame(
  node_id = V(graph_connected)$name,
  total_degree = all_degrees,
  in_degree = in_degrees,
  out_degree = out_degrees
)

# Add node attributes for additional analysis
degree_data$institution <- V(graph_connected)$institution
degree_data$subtopic <- V(graph_connected)$subtopic
degree_data$year <- V(graph_connected)$year
degree_data$citations <- V(graph_connected)$citations

cat("=== DEGREE DISTRIBUTION SUMMARY ===\n")
cat("Total degree quartiles:\n")
print(quantile(all_degrees))
cat("\nIn-degree quartiles:\n")
print(quantile(in_degrees))
cat("\nOut-degree quartiles:\n")
print(quantile(out_degrees))
```

```{r in-degree-histogram}
# In-degree distribution histogram
ggplot(degree_data, aes(x = in_degree)) +
  geom_histogram(binwidth = 1, fill = "lightblue", alpha = 0.7, color = "white") +
  labs(title = "In-Degree Distribution (Citations Received)",
       subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
       x = "In-Degree (Citations Received)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(in_degrees), by = 5))

# Print summary statistics
cat("\nIN-DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(in_degrees), 2), "\n")
cat("Median:", median(in_degrees), "\n")
cat("Mode:", names(sort(table(in_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with 0 in-degree:", sum(in_degrees == 0), "\n")
cat("Nodes with >10 in-degree:", sum(in_degrees > 10), "\n")
```

```{r out-degree-histogram}
# Out-degree distribution histogram
ggplot(degree_data, aes(x = out_degree)) +
  geom_histogram(binwidth = 1, fill = "lightcoral", alpha = 0.7, color = "white") +
  labs(title = "Out-Degree Distribution (Citations Made)",
       subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
       x = "Out-Degree (Citations Made)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(out_degrees), by = 5))

# Print summary statistics
cat("\nOUT-DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(out_degrees), 2), "\n")
cat("Median:", median(out_degrees), "\n")
cat("Mode:", names(sort(table(out_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with 0 out-degree:", sum(out_degrees == 0), "\n")
cat("Nodes with >10 out-degree:", sum(out_degrees > 10), "\n")
```

```{r total-degree-histogram}
# Total degree distribution histogram
ggplot(degree_data, aes(x = total_degree)) +
  geom_histogram(binwidth = 2, fill = "lightgreen", alpha = 0.7, color = "white") +
  labs(title = "Total Degree Distribution",
       subtitle = paste("Connected nodes (n =", vcount(graph_connected), ")"),
       x = "Total Degree (In + Out)",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, max(all_degrees), by = 10))

# Print summary statistics
cat("\nTOTAL DEGREE DISTRIBUTION STATISTICS:\n")
cat("Mean:", round(mean(all_degrees), 2), "\n")
cat("Median:", median(all_degrees), "\n")
cat("Mode:", names(sort(table(all_degrees), decreasing = TRUE))[1], "\n")
cat("Nodes with degree 1:", sum(all_degrees == 1), "\n")
cat("Nodes with degree >20:", sum(all_degrees > 20), "\n")
```

```{r degree-comparison-plot}
# Create combined degree distribution plot
degree_long <- reshape2::melt(degree_data[, c("in_degree", "out_degree", "total_degree")],
                             variable.name = "degree_type",
                             value.name = "degree_value")

# Rename for better labels
degree_long$degree_type <- factor(degree_long$degree_type,
                                 levels = c("in_degree", "out_degree", "total_degree"),
                                 labels = c("In-Degree", "Out-Degree", "Total Degree"))

# Create faceted histogram
ggplot(degree_long, aes(x = degree_value, fill = degree_type)) +
  geom_histogram(alpha = 0.7, color = "white", bins = 30) +
  facet_wrap(~degree_type, scales = "free") +
  scale_fill_manual(values = c("In-Degree" = "lightblue", 
                              "Out-Degree" = "lightcoral", 
                              "Total Degree" = "lightgreen")) +
  labs(title = "Degree Distribution Comparison",
       subtitle = "In-Degree vs Out-Degree vs Total Degree",
       x = "Degree Value",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.position = "none",
        strip.text = element_text(face = "bold"))
```

```{r largest-component-analysis}
# Analyze the largest component in detail
cat("=== LARGEST COMPONENT DETAILED ANALYSIS ===\n")

# Extract the largest weakly connected component
largest_comp_nodes <- which(weak_components$membership == which.max(weak_components$csize))
largest_component <- induced_subgraph(graph_connected, largest_comp_nodes)

cat("Largest component statistics:\n")
cat("Nodes:", vcount(largest_component), "\n")
cat("Edges:", ecount(largest_component), "\n")
cat("Density:", round(edge_density(largest_component), 6), "\n")
cat("Average in degree:", round(mean(degree(largest_component, mode = "in")), 2), "\n")
cat("Average out degree:", round(mean(degree(largest_component, mode = "out")), 2), "\n")
cat("Average degree:", round(mean(degree(largest_component, mode = "all")), 2), "\n")
cat("Diameter:", diameter(largest_component, directed = FALSE), "\n")
cat("Average path length:", round(mean_distance(largest_component, directed = FALSE), 2), "\n\n")

# Check if there are smaller components worth analyzing
if(length(unique(weak_components$csize)) > 1) {
  second_largest_size <- sort(weak_components$csize, decreasing = TRUE)[2]
  cat("Second largest component size:", second_largest_size, "\n")
  cat("Ratio (largest/second largest):", round(max(weak_components$csize) / 
  second_largest_size, 2), "\n")
}
```

## Advanced Analysis of Largest Component (Jinxi Hu)

```{r centrality-analysis}
cat("=== CENTRALITY ANALYSIS OF LARGEST COMPONENT ===\n")

# Calculate various centrality measures
cat("Calculating centrality measures...\n")

# Degree centrality (already calculated above)
degree_cent_in <- degree(largest_component, mode = "in", normalized = TRUE)
degree_cent_out <- degree(largest_component, mode = "out", normalized = TRUE)
degree_cent_all <- degree(largest_component, mode = "all", normalized = TRUE)

# Betweenness centrality
betweenness_cent <- betweenness(largest_component, directed = TRUE, normalized = TRUE)

# Closeness centrality
closeness_cent_in <- closeness(largest_component, mode = "in", normalized = TRUE)
closeness_cent_out <- closeness(largest_component, mode = "out", normalized = TRUE)

# Eigenvector centrality
eigenvector_cent <- eigen_centrality(largest_component, directed = TRUE, scale = TRUE)$vector

# PageRank centrality
pagerank_cent <- page_rank(largest_component, directed = TRUE)$vector

# Authority and Hub scores (HITS algorithm)
hits_scores <- hub_score(largest_component)
hub_cent <- hits_scores$vector
authority_cent <- authority_score(largest_component)$vector

cat("All centrality measures calculated successfully!\n\n")

# Create centrality summary
centrality_summary <- data.frame(
  node_id = V(largest_component)$name,
  degree_in = degree_cent_in,
  degree_out = degree_cent_out,
  degree_all = degree_cent_all,
  betweenness = betweenness_cent,
  closeness_in = closeness_cent_in,
  closeness_out = closeness_cent_out,
  eigenvector = eigenvector_cent,
  pagerank = pagerank_cent,
  hub = hub_cent,
  authority = authority_cent
)

# Print top nodes by different centrality measures
cat("TOP 5 NODES BY DIFFERENT CENTRALITY MEASURES:\n\n")

cat("Highest In-Degree Centrality (most cited):\n")
top_in_degree <- centrality_summary[order(centrality_summary$degree_in, decreasing = TRUE)[1:5], 
                                   c("node_id", "degree_in")]
print(top_in_degree)

cat("\nHighest PageRank (most influential):\n")
top_pagerank <- centrality_summary[order(centrality_summary$pagerank, decreasing = TRUE)[1:5], 
                                  c("node_id", "pagerank")]
print(top_pagerank)

cat("\nHighest Betweenness Centrality (most important bridges):\n")
top_betweenness <- centrality_summary[order(centrality_summary$betweenness, decreasing = TRUE)[1:5], 
                                     c("node_id", "betweenness")]
print(top_betweenness)

cat("\nHighest Authority Score (most authoritative):\n")
top_authority <- centrality_summary[order(centrality_summary$authority, decreasing = TRUE)[1:5], 
                                   c("node_id", "authority")]
print(top_authority)
```

```{r node-betweenness-analysis}
cat("=== NODE BETWEENNESS DETAILED ANALYSIS ===\n")

# Detailed betweenness analysis
betweenness_stats <- summary(betweenness_cent)
cat("Betweenness centrality statistics:\n")
print(betweenness_stats)

cat("\nNodes with highest betweenness (potential bridges):\n")
high_betweenness_threshold <- quantile(betweenness_cent, 0.95)
high_betweenness_nodes <- which(betweenness_cent >= high_betweenness_threshold)
cat("Number of high betweenness nodes (top 5%):", length(high_betweenness_nodes), "\n")

# Create betweenness distribution plot
betweenness_df <- data.frame(
  node_id = V(largest_component)$name,
  betweenness = betweenness_cent,
  institution = V(largest_component)$institution,
  subtopic = V(largest_component)$subtopic
)

# Betweenness distribution histogram
ggplot(betweenness_df, aes(x = betweenness)) +
  geom_histogram(bins = 30, fill = "purple", alpha = 0.7, color = "white") +
  labs(title = "Node Betweenness Centrality Distribution",
       subtitle = "Distribution of bridging importance in largest component",
       x = "Normalized Betweenness Centrality",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# Identify top bridging papers
cat("\nTop 10 bridging papers (highest betweenness):\n")
top_bridges <- betweenness_df[order(betweenness_df$betweenness, decreasing = TRUE)[1:10], ]
print(top_bridges[, c("node_id", "betweenness", "subtopic", "institution")])
```

```{r edge-betweenness-analysis}
cat("\n=== EDGE BETWEENNESS ANALYSIS ===\n")

# Calculate edge betweenness
cat("Calculating edge betweenness (this may take a moment)...\n")
edge_betweenness <- edge_betweenness(largest_component, directed = TRUE)

cat("Edge betweenness calculation completed!\n")
cat("Number of edges analyzed:", length(edge_betweenness), "\n")

# Edge betweenness statistics
edge_bet_stats <- summary(edge_betweenness)
cat("\nEdge betweenness statistics:\n")
print(edge_bet_stats)

# Find edges with highest betweenness
top_edge_indices <- order(edge_betweenness, decreasing = TRUE)[1:10]
top_edges <- get.edges(largest_component, top_edge_indices)

cat("\nTop 10 edges by betweenness (most critical connections):\n")
for(i in 1:10) {
  edge_idx <- top_edge_indices[i]
  from_node <- V(largest_component)$name[top_edges[i, 1]]
  to_node <- V(largest_component)$name[top_edges[i, 2]]
  bet_value <- round(edge_betweenness[edge_idx], 4)
  cat(sprintf("%d. %s -> %s (betweenness: %.4f)\n", i, from_node, to_node, bet_value))
}

# Edge betweenness distribution plot
edge_bet_df <- data.frame(edge_betweenness = edge_betweenness)
ggplot(edge_bet_df, aes(x = edge_betweenness)) +
  geom_histogram(bins = 50, fill = "orange", alpha = 0.7, color = "white") +
  labs(title = "Edge Betweenness Distribution",
       subtitle = "Distribution of edge importance as bridges in largest component",
       x = "Edge Betweenness",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

```{r community-detection-method1}
cat("\n=== COMMUNITY DETECTION - METHOD 1: LOUVAIN ALGORITHM ===\n")

# Method 1: Louvain algorithm (modularity optimization)
cat("Running Louvain algorithm for community detection...\n")

# Convert to undirected for community detection
largest_component_undirected <- as.undirected(largest_component, mode = "collapse")

# Louvain algorithm
louvain_communities <- cluster_louvain(largest_component_undirected)

cat("Louvain algorithm completed!\n")
cat("Number of communities found:", length(louvain_communities), "\n")
cat("Modularity score:", round(modularity(louvain_communities), 4), "\n")

# Community size distribution
louvain_sizes <- sizes(louvain_communities)
cat("\nCommunity sizes:\n")
print(sort(louvain_sizes, decreasing = TRUE))

cat("\nLargest 5 communities:\n")
large_communities <- sort(louvain_sizes, decreasing = TRUE)[1:5]
print(large_communities)

# Create community membership dataframe
louvain_membership <- data.frame(
  node_id = V(largest_component_undirected)$name,
  community = membership(louvain_communities),
  institution = V(largest_component_undirected)$institution,
  subtopic = V(largest_component_undirected)$subtopic
)

# Analyze community composition by subtopic
cat("\nCommunity composition analysis:\n")
for(i in 1:min(5, length(louvain_communities))) {
  cat(sprintf("\nCommunity %d (size: %d):\n", i, louvain_sizes[i]))
  community_nodes <- louvain_membership[louvain_membership$community == i, ]
  subtopic_dist <- table(community_nodes$subtopic)
  cat("Main subtopics:\n")
  print(sort(subtopic_dist, decreasing = TRUE)[1:min(3, length(subtopic_dist))])
}
```

```{r community-detection-method2}
cat("\n=== COMMUNITY DETECTION - METHOD 2: EDGE BETWEENNESS ===\n")

# Method 2: Edge betweenness-based community detection
cat("Running edge betweenness community detection...\n")

# This method removes edges with highest betweenness iteratively
edge_betweenness_communities <- cluster_edge_betweenness(largest_component_undirected, 
                                                        directed = FALSE)

cat("Edge betweenness algorithm completed!\n")
cat("Number of communities found:", length(edge_betweenness_communities), "\n")
cat("Modularity score:", round(modularity(edge_betweenness_communities), 4), "\n")

# Community size distribution
eb_sizes <- sizes(edge_betweenness_communities)
cat("\nCommunity sizes:\n")
print(sort(eb_sizes, decreasing = TRUE))

# Compare the two methods
cat("\n=== COMPARISON OF COMMUNITY DETECTION METHODS ===\n")
cat("Louvain - Communities:", length(louvain_communities), 
    "| Modularity:", round(modularity(louvain_communities), 4), "\n")
cat("Edge Betweenness - Communities:", length(edge_betweenness_communities), 
    "| Modularity:", round(modularity(edge_betweenness_communities), 4), "\n")

# Create comparison plot
community_comparison <- data.frame(
  Method = c("Louvain", "Edge Betweenness"),
  Communities = c(length(louvain_communities), length(edge_betweenness_communities)),
  Modularity = c(modularity(louvain_communities), modularity(edge_betweenness_communities))
)

# Plot comparison
p1 <- ggplot(community_comparison, aes(x = Method, y = Communities, fill = Method)) +
  geom_bar(stat = "identity", alpha = 0.7) +
  scale_fill_manual(values = c("Louvain" = "lightblue", 
                               "Edge Betweenness" = "lightcoral")) +
  labs(title = "Number of Communities",
       y = "Number of Communities") +
  theme_minimal() +
  theme(legend.position = "none")

p2 <- ggplot(community_comparison, aes(x = Method, y = Modularity, fill = Method)) +
  geom_bar(stat = "identity", alpha = 0.7) +
  scale_fill_manual(values = c("Louvain" = "lightblue", 
                               "Edge Betweenness" = "lightcoral")) +
  labs(title = "Modularity Score",
       y = "Modularity") +
  theme_minimal() +
  theme(legend.position = "none")

# Display plots side by side
grid.arrange(p1, p2, ncol = 2, 
             top = "Community Detection Methods Comparison")
```

```{r centrality-correlation-analysis}
cat("\n=== CENTRALITY MEASURES CORRELATION ANALYSIS ===\n")

# Analyze correlations between different centrality measures
centrality_cor_data <- centrality_summary[, 
                              c("degree_in", "degree_out", "betweenness", 
                                "closeness_in", "closeness_out", 
                                "eigenvector", "pagerank", "authority", "hub")]

# Calculate correlation matrix
cor_matrix <- cor(centrality_cor_data, use = "complete.obs")
cat("Correlation matrix calculated\n")
print(round(cor_matrix, 3))

# Create correlation heatmap
cor_melted <- melt(cor_matrix)
ggplot(cor_melted, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                      midpoint = 0, limit = c(-1,1), space = "Lab",
                      name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        plot.title = element_text(hjust = 0.5)) +
  labs(title = "Centrality Measures Correlation Matrix",
       x = "", y = "") +
  geom_text(aes(label = round(value, 2)), size = 3)
```